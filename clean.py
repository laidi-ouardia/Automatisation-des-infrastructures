# -*- coding: utf-8 -*-
"""clean.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y8W4Clq1oWKjb0GfUC6zMwYQUWNlC5VJ
"""

import  csv
import subprocess
from pyspark.sql import SparkSession
from pyspark.sql.functions import col,lit

spark= SparkSession.builder.getOrCreate()
df = spark.read.csv('reponse.csv',sep=';',header= True)
df.na.drop("all").show()
df.printSchema()
df.show()
df.withColumn("Annee",lit("Year")).show()
df.withColumn("mois",lit("month")).show()
df.withColumn("jour",lit("day")).show()
df.schema.names
#df.write.parquet("dfclean.parquet")
dfparquet= spark.read.parquet("dfclean.parquet")
subprocess.call(['hadoop fs -copyFromLocal dfclean.parquet hdfs:///data/groupe16'], shell=True)
subprocess.call(['hadoop fs -copyFromLocal table2.csv hdfs:///data/groupe16'],shell= True)
subprocess.call(['hadoop fs -copyFromLocal reponse.csv hdfs:///data/groupe16'],shell=True)